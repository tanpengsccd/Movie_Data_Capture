# ç¨‹åºå…¥å£
from collections import namedtuple
from itertools import groupby
from operator import itemgetter
from types import SimpleNamespace
import argparse
import json
import os
import random
import re
import sys
import time
import shutil
import typing
import pydash
import urllib3
import signal
import platform
from ConfigModel import ConfigModel
from PathNameProcessor import PathNameProcessor
import number_parser
import config

from config import Main_Mode
from datetime import datetime, timedelta
from lxml import etree
from pathlib import Path
from opencc import OpenCC

from scraper import get_data_from_json
from ADC_function import file_modification_days, get_html, parallel_download_files
from number_parser import get_number
from core import core_main, core_main_no_net_op, moveFailedFolder, debug_print


# æ›´æ–°ç‰ˆæœ¬å·
def check_update(local_version):
    htmlcode = get_html("https://api.github.com/repos/yoshiko2/Movie_Data_Capture/releases/latest")
    data = json.loads(htmlcode)
    remote = int(data["tag_name"].replace(".", ""))
    local_version = int(local_version.replace(".", ""))
    if local_version < remote:
        print("[*]" + ("* New update " + str(data["tag_name"]) + " *").center(54))
        print("[*]" + "â†“ Download â†“".center(54))
        print("[*]https://github.com/yoshiko2/Movie_Data_Capture/releases")
        print("[*]======================================================")


def argparse_function(ver: str, conf: config.Config) -> typing.Tuple[str, str, str, str, bool, bool, str, str]:
    parser = argparse.ArgumentParser(epilog=f"Load Config file '{conf.ini_path}'.")
    parser.add_argument("file", default='', nargs='?', help="Single Movie file path.")
    parser.add_argument("-p", "--path", default='', nargs='?', help="Analysis folder path.")
    parser.add_argument("-m", "--main-mode", default='', nargs='?',
                        help="Main mode. 1:Scraping 2:Organizing 3:Scraping in analysis folder")
    parser.add_argument("-n", "--number", default='', nargs='?', help="Custom file number of single movie file.")
    # parser.add_argument("-C", "--config", default='config.ini', nargs='?', help="The config file Path.")
    parser.add_argument("-L", "--link-mode", default='', nargs='?',
                        help="Create movie file link. 0:moving movie file, do not create link 1:soft link 2:try hard link first")
    default_logdir = str(Path.home() / '.mlogs')
    parser.add_argument("-o", "--log-dir", dest='logdir', default=default_logdir, nargs='?',
                        help=f"""Duplicate stdout and stderr to logfiles in logging folder, default on.
        default folder for current user: '{default_logdir}'. Change default folder to an empty file,
        or use --log-dir= to turn log off.""")
    parser.add_argument("-q", "--regex-query", dest='regexstr', default='', nargs='?',
                        help="python re module regex filepath filtering.")
    parser.add_argument("-d", "--nfo-skip-days", dest='days', default='', nargs='?',
                        help="Override nfo_skip_days value in config.")
    parser.add_argument("-c", "--stop-counter", dest='cnt', default='', nargs='?',
                        help="Override stop_counter value in config.")
    parser.add_argument("-R", "--rerun-delay", dest='delaytm', default='', nargs='?',
                        help="Delay (eg. 1h10m30s or 60 (second)) time and rerun, until all movies proceed. Note: stop_counter value in config or -c must none zero.")
    parser.add_argument("-i", "--ignore-failed-list", action="store_true", help="Ignore failed list '{}'".format(
        os.path.join(os.path.abspath(conf.failed_folder()), 'failed_list.txt')))
    parser.add_argument("-a", "--auto-exit", action="store_true",
                        help="Auto exit after program complete")
    parser.add_argument("-g", "--debug", action="store_true",
                        help="Turn on debug mode to generate diagnostic log for issue report.")
    parser.add_argument("-N", "--no-network-operation", action="store_true",
                        help="No network query, do not get metadata, for cover cropping purposes, only takes effect when main mode is 3.")
    parser.add_argument("-w", "--website", dest='site', default='', nargs='?',
                        help="Override [priority]website= in config.")
    parser.add_argument("-D", "--download-images", dest='dnimg', action="store_true",
                        help="Override [common]download_only_missing_images=0 force invoke image downloading.")
    parser.add_argument("-C", "--config-override", dest='cfgcmd', action='append', nargs=1,
                        help="Common use config override. Grammar: section:key=value[;[section:]key=value] eg. 'de:s=1' or 'debug_mode:switch=1' override[debug_mode]switch=1 Note:this parameters can be used multiple times")
    parser.add_argument("-z", "--zero-operation", dest='zero_op', action="store_true",
                        help="""Only show job list of files and numbers, and **NO** actual operation
is performed. It may help you correct wrong numbers before real job.""")
    parser.add_argument("-v", "--version", action="version", version=ver)
    parser.add_argument("-s", "--search", default='', nargs='?', help="Search number")
    parser.add_argument("-ss", "--specified-source", default='', nargs='?', help="specified Source.")
    parser.add_argument("-su", "--specified-url", default='', nargs='?', help="specified Url.")

    args = parser.parse_args()

    def set_natural_number_or_none(sk, value):
        if isinstance(value, str) and value.isnumeric() and int(value) >= 0:
            conf.set_override(f'{sk}={value}')

    def set_str_or_none(sk, value):
        if isinstance(value, str) and len(value):
            conf.set_override(f'{sk}={value}')

    def set_bool_or_none(sk, value):
        if isinstance(value, bool) and value:
            conf.set_override(f'{sk}=1')

    set_natural_number_or_none("common:main_mode", args.main_mode)
    set_natural_number_or_none("common:link_mode", args.link_mode)
    set_str_or_none("common:source_folder", args.path)
    set_bool_or_none("common:auto_exit", args.auto_exit)
    set_natural_number_or_none("common:nfo_skip_days", args.days)
    set_natural_number_or_none("advenced_sleep:stop_counter", args.cnt)
    set_bool_or_none("common:ignore_failed_list", args.ignore_failed_list)
    set_str_or_none("advenced_sleep:rerun_delay", args.delaytm)
    set_str_or_none("priority:website", args.site)
    if isinstance(args.dnimg, bool) and args.dnimg:
        conf.set_override("common:download_only_missing_images=0")
    set_bool_or_none("debug_mode:switch", args.debug)
    if isinstance(args.cfgcmd, list):
        for cmd in args.cfgcmd:
            conf.set_override(cmd[0])

    no_net_op = False
    if conf.main_mode() == config.Main_Mode.ScrapingInAnalysisFolder:
        no_net_op = args.no_network_operation
        if no_net_op:
            conf.set_override("advenced_sleep:stop_counter=0;advenced_sleep:rerun_delay=0s;face:aways_imagecut=1")

    return args.file, args.number, args.logdir, args.regexstr, args.zero_op, no_net_op, args.search, args.specified_source, args.specified_url


class OutLogger(object):
    def __init__(self, logfile) -> None:
        self.term = sys.stdout
        self.log = open(logfile, "w", encoding='utf-8', buffering=1)
        self.filepath = logfile

    def __del__(self):
        self.close()

    def __enter__(self):
        pass

    def __exit__(self, *args):
        self.close()

    def write(self, msg):
        self.term.write(msg)
        self.log.write(msg)

    def flush(self):
        if 'flush' in dir(self.term):
            self.term.flush()
        if 'flush' in dir(self.log):
            self.log.flush()
        if 'fileno' in dir(self.log):
            os.fsync(self.log.fileno())

    def close(self):
        if self.term is not None:
            sys.stdout = self.term
            self.term = None
        if self.log is not None:
            self.log.close()
            self.log = None


class ErrLogger(OutLogger):

    def __init__(self, logfile) -> None:
        self.term = sys.stderr
        self.log = open(logfile, "w", encoding='utf-8', buffering=1)
        self.filepath = logfile

    def close(self):
        if self.term is not None:
            sys.stderr = self.term
            self.term = None

        if self.log is not None:
            self.log.close()
            self.log = None


def dupe_stdout_to_logfile(logdir: str):
    if not isinstance(logdir, str) or len(logdir) == 0:
        return
    log_dir = Path(logdir)
    if not log_dir.exists():
        try:
            log_dir.mkdir(parents=True, exist_ok=True)
        except:
            pass
    if not log_dir.is_dir():
        return  # Tips for disabling logs by change directory to a same name empty regular file
    abslog_dir = log_dir.resolve()
    log_tmstr = datetime.now().strftime("%Y%m%dT%H%M%S")
    logfile = abslog_dir / f'mdc_{log_tmstr}.txt'
    errlog = abslog_dir / f'mdc_{log_tmstr}_err.txt'

    sys.stdout = OutLogger(logfile)
    sys.stderr = ErrLogger(errlog)


def close_logfile(logdir: str):
    if not isinstance(logdir, str) or len(logdir) == 0 or not os.path.isdir(logdir):
        return
    # æ—¥å¿—å…³é—­å‰ä¿å­˜æ—¥å¿—è·¯å¾„
    filepath = None
    try:
        filepath = sys.stdout.filepath
    except:
        pass
    sys.stdout.close()
    sys.stderr.close()
    log_dir = Path(logdir).resolve()
    if isinstance(filepath, Path):
        print(f"Log file '{filepath}' saved.")
        assert (filepath.parent.samefile(log_dir))
    # æ¸…ç†ç©ºæ–‡ä»¶
    for f in log_dir.glob(r'*_err.txt'):
        if f.stat().st_size == 0:
            try:
                f.unlink(missing_ok=True)
            except:
                pass
    # åˆå¹¶æ—¥å¿— åªæ£€æµ‹æ—¥å¿—ç›®å½•å†…çš„æ–‡æœ¬æ—¥å¿—ï¼Œå¿½ç•¥å­ç›®å½•ã€‚ä¸‰å¤©å‰çš„æ—¥å¿—ï¼ŒæŒ‰æ—¥åˆå¹¶ä¸ºå•ä¸ªæ—¥å¿—ï¼Œä¸‰ä¸ªæœˆå‰çš„æ—¥å¿—ï¼Œ
    # æŒ‰æœˆåˆå¹¶ä¸ºå•ä¸ªæœˆå¿—ï¼Œå»å¹´åŠä»¥å‰çš„æœˆå¿—ï¼Œä»Šå¹´4æœˆä»¥åå°†ä¹‹æŒ‰å¹´åˆå¹¶ä¸ºå¹´å¿—
    # æµ‹è¯•æ­¥éª¤ï¼š
    """
    LOGDIR=/tmp/mlog
    mkdir -p $LOGDIR
    for f in {2016..2020}{01..12}{01..28};do;echo $f>$LOGDIR/mdc_${f}T235959.txt;done
    for f in {01..09}{01..28};do;echo 2021$f>$LOGDIR/mdc_2021${f}T235959.txt;done
    for f in {00..23};do;echo 20211001T$f>$LOGDIR/mdc_20211001T${f}5959.txt;done
    echo "$(ls -1 $LOGDIR|wc -l) files in $LOGDIR"
    # 1932 files in /tmp/mlog
    mdc -zgic1 -d0 -m3 -o $LOGDIR
    # python3 ./__init__.py -zgic1 -o $LOGDIR
    ls $LOGDIR
    # rm -rf $LOGDIR
    """
    today = datetime.today()
    # ç¬¬ä¸€æ­¥ï¼Œåˆå¹¶åˆ°æ—¥ã€‚3å¤©å‰çš„æ—¥å¿—ï¼Œæ–‡ä»¶åæ˜¯åŒä¸€å¤©çš„åˆå¹¶ä¸ºä¸€ä»½æ—¥å¿—
    for i in range(1):
        txts = [f for f in log_dir.glob(r'*.txt') if re.match(r'^mdc_\d{8}T\d{6}$', f.stem, re.A)]
        if not txts or not len(txts):
            break
        e = [f for f in txts if '_err' in f.stem]
        txts.sort()
        tmstr_3_days_ago = (today.replace(hour=0) - timedelta(days=3)).strftime("%Y%m%dT99")
        deadline_day = f'mdc_{tmstr_3_days_ago}'
        day_merge = [f for f in txts if f.stem < deadline_day]
        if not day_merge or not len(day_merge):
            break
        cutday = len('T235959.txt')  # cut length mdc_20201201|T235959.txt
        for f in day_merge:
            try:
                day_file_name = str(f)[:-cutday] + '.txt'  # mdc_20201201.txt
                with open(day_file_name, 'a', encoding='utf-8') as m:
                    m.write(f.read_text(encoding='utf-8'))
                f.unlink(missing_ok=True)
            except:
                pass
    # ç¬¬äºŒæ­¥ï¼Œåˆå¹¶åˆ°æœˆ
    for i in range(1):  # åˆ©ç”¨1æ¬¡å¾ªç¯çš„breakè·³åˆ°ç¬¬äºŒæ­¥ï¼Œé¿å…å¤§å—ifç¼©è¿›æˆ–è€…ä½¿ç”¨gotoè¯­æ³•
        txts = [f for f in log_dir.glob(r'*.txt') if re.match(r'^mdc_\d{8}$', f.stem, re.A)]
        if not txts or not len(txts):
            break
        txts.sort()
        tmstr_3_month_ago = (today.replace(day=1) - timedelta(days=3 * 30)).strftime("%Y%m32")
        deadline_month = f'mdc_{tmstr_3_month_ago}'
        month_merge = [f for f in txts if f.stem < deadline_month]
        if not month_merge or not len(month_merge):
            break
        tomonth = len('01.txt')  # cut length mdc_202012|01.txt
        for f in month_merge:
            try:
                month_file_name = str(f)[:-tomonth] + '.txt'  # mdc_202012.txt
                with open(month_file_name, 'a', encoding='utf-8') as m:
                    m.write(f.read_text(encoding='utf-8'))
                f.unlink(missing_ok=True)
            except:
                pass
    # ç¬¬ä¸‰æ­¥ï¼Œæœˆåˆå¹¶åˆ°å¹´
    for i in range(1):
        if today.month < 4:
            break
        mons = [f for f in log_dir.glob(r'*.txt') if re.match(r'^mdc_\d{6}$', f.stem, re.A)]
        if not mons or not len(mons):
            break
        mons.sort()
        deadline_year = f'mdc_{today.year - 1}13'
        year_merge = [f for f in mons if f.stem < deadline_year]
        if not year_merge or not len(year_merge):
            break
        toyear = len('12.txt')  # cut length mdc_2020|12.txt
        for f in year_merge:
            try:
                year_file_name = str(f)[:-toyear] + '.txt'  # mdc_2020.txt
                with open(year_file_name, 'a', encoding='utf-8') as y:
                    y.write(f.read_text(encoding='utf-8'))
                f.unlink(missing_ok=True)
            except:
                pass
    # ç¬¬å››æ­¥ï¼Œå‹ç¼©å¹´å¿— å¦‚æœæœ‰å‹ç¼©éœ€æ±‚ï¼Œè¯·è‡ªè¡Œæ‰‹å·¥å‹ç¼©ï¼Œæˆ–è€…ä½¿ç”¨å¤–éƒ¨è„šæœ¬æ¥å®šæ—¶å®Œæˆã€‚æ¨ènongnuçš„lzipï¼Œå¯¹äº
    # è¿™ç§ç²’åº¦çš„æ–‡æœ¬æ—¥å¿—ï¼Œå‹ç¼©æ¯”æ˜¯ç›®å‰æœ€å¥½çš„ã€‚lzip -9çš„è¿è¡Œå‚æ•°ä¸‹ï¼Œæ—¥å¿—å‹ç¼©æ¯”è¦é«˜äºxz -9ï¼Œè€Œä¸”å†…å­˜å ç”¨æ›´å°‘ï¼Œ
    # å¤šæ ¸åˆ©ç”¨ç‡æ›´é«˜(plzipå¤šçº¿ç¨‹ç‰ˆæœ¬)ï¼Œè§£å‹é€Ÿåº¦æ›´å¿«ã€‚å‹ç¼©åçš„å¤§å°å·®ä¸å¤šæ˜¯æœªå‹ç¼©æ—¶çš„2.4%åˆ°3.7%å·¦å³ï¼Œ
    # 100MBçš„æ—¥å¿—æ–‡ä»¶èƒ½ç¼©å°åˆ°3.7MBã€‚
    return filepath


# é€€å‡ºç¨‹åº
def signal_handler(*args):
    print('[!]Ctrl+C detected, Exit.')
    os._exit(9)


# è°ƒè¯•æ¨¡å¼å¼€å…³
def sigdebug_handler(*args):
    conf = config.getInstance()
    conf.set_override(f"debug_mode:switch={int(not conf.debug())}")
    print(f"[!]Debug {('oFF', 'On')[int(conf.debug())]}")


# è·å–å¾…å¤„ç†æ–‡ä»¶åˆ—è¡¨: ä¼šæŒ‰é…ç½®è§„åˆ™è¿‡æ»¤ä¸ç›¸å…³æ–‡ä»¶,æ–°å¢å¤±è´¥æ–‡ä»¶åˆ—è¡¨è·³è¿‡å¤„ç†ï¼ŒåŠ.nfoä¿®æ”¹å¤©æ•°è·³è¿‡å¤„ç†ï¼Œæç¤ºè·³è¿‡è§†é¢‘æ€»æ•°ï¼Œè°ƒè¯•æ¨¡å¼(-g)ä¸‹è¯¦ç»†è¢«è·³è¿‡æ–‡ä»¶ï¼Œè·³è¿‡å°å¹¿å‘Š
def movie_lists(source_folder, regexstr: str) -> typing.List[str]:
    debug = G_conf.debug()
    nfo_skip_days = G_conf.nfo_skip_days()
    link_mode = G_conf.link_mode()
    file_type = G_conf.media_type().lower().split(",")
    trailerRE = re.compile(r'-trailer\.', re.IGNORECASE)
    cliRE = re.compile(regexstr, re.IGNORECASE)  if isinstance(regexstr, str) and len(regexstr) else None
    failed_list_txt_path = Path(G_conf.failed_folder()).resolve() / 'failed_list.txt'
    # æå–å†å²åˆ®å‰Šå¤±è´¥çš„è·¯å¾„
    failed_set = set()
    if (G_conf.main_mode() == Main_Mode.ScrapingInAnalysisFolder or link_mode) and not G_conf.ignore_failed_list():
        try:
            flist = failed_list_txt_path.read_text(encoding='utf-8').splitlines()
            failed_set = set(flist)
            if len(flist) != len(failed_set):  # æ£€æŸ¥å»é‡å¹¶å†™å›ï¼Œä½†æ˜¯ä¸æ”¹å˜failed_list.txtå†…æ¡ç›®çš„å…ˆåæ¬¡åºï¼Œé‡å¤çš„åªä¿ç•™æœ€åçš„
                fset = failed_set.copy()
                for i in range(len(flist) - 1, -1, -1):
                    fset.remove(flist[i]) if flist[i] in fset else flist.pop(i)
                failed_list_txt_path.write_text('\n'.join(flist) + '\n', encoding='utf-8')
                assert len(fset) == 0 and len(flist) == len(failed_set)
        except:
            pass
    if not Path(source_folder).is_dir():
        print('[-]Source folder not found!')
        return []
    total = []
    source = Path(source_folder).resolve()
    skip_failed_cnt, skip_nfo_days_cnt = 0, 0
    escape_folder_set = set(re.split("[,ï¼Œ]", G_conf.escape_folder()))
    # éå†æ–‡ä»¶å¤¹
    for full_name in source.glob(r'**/*'):
        # åŸè·¯å¾„åˆ®å‰Š
        if G_conf.main_mode() != Main_Mode.ScrapingInAnalysisFolder and set(full_name.parent.parts) & escape_folder_set:
            continue
        # ä¸æ˜¯æ–‡ä»¶
        if not full_name.is_file():
            continue
        # ä¸æ˜¯æŒ‡å®šç±»å‹
        if not full_name.suffix.lower() in file_type:
            continue
        absf = str(full_name)
        if absf in failed_set:
            skip_failed_cnt += 1
            if debug:
                print('[!]Skip failed movie:', absf)
            continue
        is_sym = full_name.is_symlink()
        if G_conf.main_mode() != Main_Mode.ScrapingInAnalysisFolder and (is_sym or (
                full_name.stat().st_nlink > 1 and not G_conf.scan_hardlink())):  # çŸ­è·¯å¸ƒå°” ç¬¦å·é“¾æ¥ä¸å–stat()ï¼Œå› ä¸ºç¬¦å·é“¾æ¥å¯èƒ½æŒ‡å‘ä¸å­˜åœ¨ç›®æ ‡
            continue  # æ¨¡å¼ä¸ç­‰äº3ä¸‹è·³è¿‡è½¯è¿æ¥å’Œæœªé…ç½®ç¡¬é“¾æ¥åˆ®å‰Š 
        # è°ƒè¯•ç”¨0å­—èŠ‚æ ·æœ¬å…è®¸é€šè¿‡ï¼Œå»é™¤å°äº120MBçš„å¹¿å‘Š'è‹è€å¸ˆå¼ºåŠ›æ¨è.mp4'(102.2MB)'é»‘é“æ€»è£.mp4'(98.4MB)'æœ‰è¶£çš„å¦¹å­æ¿€æƒ…è¡¨æ¼”.MP4'(95MB)'æœ‰è¶£çš„è‡ºç£å¦¹å¦¹ç›´æ’­.mp4'(15.1MB)
        movie_size = 0 if is_sym else full_name.stat().st_size  # åŒä¸Š ç¬¦å·é“¾æ¥ä¸å–stat()åŠst_sizeï¼Œç›´æ¥èµ‹0è·³è¿‡å°è§†é¢‘æ£€æµ‹
        # if 0 < movie_size < 125829120:  # 1024*1024*120=125829120
        #     continue
        if cliRE and not cliRE.search(absf) or trailerRE.search(full_name.name):
            continue
        if G_conf.main_mode() == Main_Mode.ScrapingInAnalysisFolder:
            nfo = full_name.with_suffix('.nfo')
            if not nfo.is_file():
                if debug:
                    print(f"[!]Metadata {nfo.name} not found for '{absf}'")
            elif nfo_skip_days > 0 and file_modification_days(nfo) <= nfo_skip_days:
                skip_nfo_days_cnt += 1
                if debug:
                    print(f"[!]Skip movie by it's .nfo which modified within {nfo_skip_days} days: '{absf}'")
                continue
        total.append(absf)

    if skip_failed_cnt:
        print(f"[!]Skip {skip_failed_cnt} movies in failed list '{failed_list_txt_path}'.")
    if skip_nfo_days_cnt:
        print(
            f"[!]Skip {skip_nfo_days_cnt} movies in source folder '{source}' who's .nfo modified within {nfo_skip_days} days.")
    if nfo_skip_days <= 0 or not link_mode or G_conf.main_mode() == Main_Mode.ScrapingInAnalysisFolder:
        return total
    # è½¯è¿æ¥æ–¹å¼ï¼Œå·²ç»æˆåŠŸå‰Šåˆ®çš„ä¹Ÿéœ€è¦ä»æˆåŠŸç›®å½•ä¸­æ£€æŸ¥.nfoæ›´æ–°å¤©æ•°ï¼Œè·³è¿‡Nå¤©å†…æ›´æ–°è¿‡çš„
    skip_numbers = set()
    success_folder = Path(G_conf.success_folder()).resolve()
    for f in success_folder.glob(r'**/*'):
        if not re.match(r'\.nfo$', f.suffix, re.IGNORECASE):
            continue
        if file_modification_days(f) > nfo_skip_days:
            continue
        number = get_number(False, f.stem)
        if not number:
            continue
        skip_numbers.add(number.lower())

    rm_list = []
    for f in total:
        n_number = get_number(False, os.path.basename(f))
        if n_number and n_number.lower() in skip_numbers:
            rm_list.append(f)
    for f in rm_list:
        total.remove(f)
        if debug:
            print(f"[!]Skip file successfully processed within {nfo_skip_days} days: '{f}'")
    if len(rm_list):
        print(
            f"[!]Skip {len(rm_list)} movies in success folder '{success_folder}' who's .nfo modified within {nfo_skip_days} days.")

    return total


# ç”Ÿæˆå¤±è´¥æ–‡ä»¶å¤¹
def create_failed_folder(failed_folder: str):
    """
    æ–°å»ºfailedæ–‡ä»¶å¤¹
    """
    if not os.path.exists(failed_folder):
        try:
            os.makedirs(failed_folder)
        except:
            print(f"[-]Fatal error! Can not make folder '{failed_folder}'")
            os._exit(0)


# åˆ é™¤ç©ºæ–‡ä»¶å¤¹
def rm_empty_folder(path):
    abspath = os.path.abspath(path)
    deleted = set()
    for current_dir, subdirs, files in os.walk(abspath, topdown=False):
        try:
            still_has_subdirs = any(_ for subdir in subdirs if os.path.join(current_dir, subdir) not in deleted)
            if not any(files) and not still_has_subdirs and not os.path.samefile(path, current_dir):
                os.rmdir(current_dir)
                deleted.add(current_dir)
                print('[+]Deleting empty folder', current_dir)
        except:
            pass


def get_numbers(paths: typing.List[str]):
    """æå–å¯¹åº”è·¯å¾„çš„ç•ªå·+é›†æ•°,é›†æ•°å¯èƒ½å«C(ä¸­æ–‡å­—å¹•)ä½†éåˆ†é›†"""

    def get_number(filepath, absolute_path=False):
        """
        è·å–ç•ªå·ï¼Œé›†æ•°
        :param filepath:
        :param absolute_path:
        :return:
        """
        name = filepath.upper()  # è½¬å¤§å†™
        if absolute_path:
            name = name.replace('\\', '/')
        # ç§»é™¤å¹²æ‰°å­—æ®µ
        name = PathNameProcessor.remove_distractions(name)
        # æŠ½å– æ–‡ä»¶è·¯å¾„ä¸­å¯èƒ½å­˜åœ¨çš„å°¾éƒ¨é›†æ•°ï¼Œå’ŒæŠ½å–å°¾éƒ¨é›†æ•°çš„åçš„æ–‡ä»¶è·¯å¾„
        suffix_episode, name = PathNameProcessor.extract_suffix_episode(name)
        # æŠ½å– æ–‡ä»¶è·¯å¾„ä¸­å¯èƒ½å­˜åœ¨çš„ ç•ªå·åè·Ÿéšçš„é›†æ•° å’Œ å¤„ç†åç•ªå·
        code_number, episode_behind_code = PathNameProcessor.extract_code(name)
        # æ— ç•ªå· åˆ™è®¾ç½®ç©ºå­—ç¬¦
        code_number = code_number if code_number else ''
        # ä¼˜å…ˆå–å°¾éƒ¨é›†æ•°ï¼Œæ— åˆ™å–ç•ªå·åçš„é›†æ•°ï¼ˆå‡ ç‡ä½ï¼‰ï¼Œéƒ½æ— åˆ™ä¸ºç©ºå­—ç¬¦
        episode = suffix_episode or episode_behind_code or None

        # return namedtuple('R', ['code', 'episode'])(code_number,episode) 
        return SimpleNamespace(code=code_number, episode=episode, isCn=False)

    # paths æŒ‰ code_number åˆ†ç»„ ä¸ºæ–°å­—å…¸
    if G_ini_conf.common.movie_type == 1:
        path_list = list(map((lambda x: SimpleNamespace(path=x, result=get_number(x))), paths))
    else:
        path_list = list(map((lambda x: SimpleNamespace(path=x, result=number_parser.get_number_tp(x))), paths))
    grouped_data = {k: list(v) for k, v in groupby(path_list, key=lambda x: x.result.code)}

    # å¤„ç†: å¦‚æœåŒcodeæ—¶, episode æœ‰cæ— b,a ,åˆ™ä¸ºä¸­æ–‡å­—å¹•è§†é¢‘ å¹¶éepisode
    for codeKey, itemList in grouped_data.items():
        for i in itemList:
            if (
                    (ep := i.result.episode) and
                    ep is not None and ep.lower() == 'c' and
                    not pydash.find(itemList, lambda x: (x.result.episode or '').lower() in ['a', 'b'])
            ):
                i.result.episode = None
                i.result.isCn = True
            else:
                continue

    return path_list


# ç”Ÿæˆæ•°æ®å¹¶ç§»åŠ¨
def create_data_and_move(movie_path: str, zero_op: bool, no_net_op: bool, oCC):
    """
ç”Ÿæˆæ•°æ®å¹¶ç§»åŠ¨
    :param movie_path:è·¯å¾„
    :param zero_op:æ˜¯å¦ä¸º ä¸æ“ä½œ
    :param no_net_op:æ˜¯å¦ä¸º æ— ç½‘ç»œæ“ä½œ

    """
    # Normalized number, eg: 111xxx-222.mp4 -> xxx-222.mp4
    debug = config.getInstance().debug()
    # å¦‚æœé…ç½®é¡¹ test_movie_list 
    # â¤ï¸è·å–ç•ªå·æ ¸å¿ƒå¤„ç†â¤ï¸  
    n_number = get_number(debug, os.path.basename(movie_path))
    movie_path = os.path.abspath(movie_path)

    if debug is True:
        print(f"[!] [{n_number}] As Number Processing for '{movie_path}'")
        if zero_op:
            return
        if n_number:
            if no_net_op:
                core_main_no_net_op(movie_path, n_number)
            else:
                core_main(movie_path, n_number, oCC)
        else:
            print("[-] number empty ERROR")
            moveFailedFolder(movie_path)
        print("[*]======================================================")
    else:
        try:
            print(f"[!] [{n_number}] As Number Processing for '{movie_path}'")
            if zero_op:
                # zero operation å¤§æ¦‚æ˜¯ ä¸æ“ä½œçš„æ„æ€å§...
                return
            if n_number:
                if no_net_op:
                    core_main_no_net_op(movie_path, n_number)
                else:
                    # æ ¸å¿ƒâ¤ï¸
                    core_main(movie_path, n_number, oCC)
            else:
                raise ValueError("number empty")
            print("[*]======================================================")
        except Exception as err:
            print(f"[-] [{movie_path}] ERROR:")
            print('[-]', err)

            try:
                moveFailedFolder(movie_path)
            except Exception as err:
                print('[!]', err)


def create_data_and_move_with_custom_number(file_path: str, custom_number, oCC, specified_source, specified_url):
    conf = config.getInstance()
    file_name = os.path.basename(file_path)
    try:
        print("[!] [{1}] As Number Processing for '{0}'".format(file_path, custom_number))
        if custom_number:
            core_main(file_path, custom_number, oCC, specified_source, specified_url)
        else:
            print("[-] number empty ERROR")
        print("[*]======================================================")
    except Exception as err:
        print("[-] [{}] ERROR:".format(file_path))
        print('[-]', err)

        if conf.link_mode():
            print("[-]Link {} to failed folder".format(file_path))
            os.symlink(file_path, os.path.join(conf.failed_folder(), file_name))
        else:
            try:
                print("[-]Move [{}] to failed folder".format(file_path))
                shutil.move(file_path, os.path.join(conf.failed_folder(), file_name))
            except Exception as err:
                print('[!]', err)


# å¼€å§‹å¤„ç† å¯åŠ¨çš„å…¥å£ â¤ï¸
def main(args: tuple) -> Path:
    # è·å–é…ç½® zero_op æ˜¯å¦ä¸º ä¸æ“ä½œ:åªè·å–ç•ªå·, no_net_op  ç¦»çº¿æ“ä½œ(ä¸è”ç½‘)
    (single_file_path, custom_number, logdir, regexstr, zero_op, no_net_op, search, specified_source,
     specified_url) = args

    folder_path = ""

    signal.signal(signal.SIGINT, signal_handler)
    if sys.platform == 'win32':
        signal.signal(signal.SIGBREAK, sigdebug_handler)
    else:
        signal.signal(signal.SIGWINCH, sigdebug_handler)
    dupe_stdout_to_logfile(logdir)

    platform_total = str(
        ' - ' + platform.platform() + ' \n[*] - ' + platform.machine() + ' - Python-' + platform.python_version())

    print('[*]================= Movie Data Capture =================')
    print('[*]' + version.center(54))
    print('[*]======================================================')
    print('[*]' + platform_total)
    print('[*]======================================================')
    print('[*] - ä¸¥ç¦åœ¨å¢™å†…å®£ä¼ æœ¬é¡¹ç›® - ')
    print('[*]======================================================')

    start_time = time.time()
    print('[+]Start at', time.strftime("%Y-%m-%d %H:%M:%S"))

    print(f"[+]Load Config file '{G_conf.ini_path}'.")
    if G_conf.debug():
        print('[+]Enable debug')
    if G_conf.link_mode() in (1, 2):
        print('[!]Enable {} link'.format(('soft', 'hard')[G_conf.link_mode() - 1]))
    if len(sys.argv) > 1:
        print('[!]CmdLine:', " ".join(sys.argv[1:]))
    print('[+]Main Working mode ## {}: {} ## {}{}{}'
          .format(*(G_conf.main_mode().value, G_conf.main_mode().name,
                    "" if not G_conf.multi_threading() else ", multi_threading on",
                    "" if G_conf.nfo_skip_days() == 0 else f", nfo_skip_days={G_conf.nfo_skip_days()}",
                    "" if G_conf.stop_counter() == 0 else f", stop_counter={G_conf.stop_counter()}"
                    ) if not single_file_path else ('-', 'Single File', '', '', ''))
          )
    # æ›´æ–°æ£€æŸ¥
    if G_conf.update_check():
        try:
            check_update(version)

            # Download Mapping Table, parallel version
            def fmd(f) -> typing.Tuple[str, Path]:
                return ('https://raw.githubusercontent.com/yoshiko2/Movie_Data_Capture/master/MappingTable/' + f,
                        Path.home() / '.local' / 'share' / 'mdc' / f)

            map_tab = (fmd('mapping_actor.xml'), fmd('mapping_info.xml'), fmd('c_number.json'))
            for k, v in map_tab:
                if v.exists():
                    if file_modification_days(str(v)) >= G_conf.mapping_table_validity():
                        print("[+]Mapping Table Out of date! Remove", str(v))
                        os.remove(str(v))
            res = parallel_download_files(((k, v) for k, v in map_tab if not v.exists()))
            for i, fp in enumerate(res, start=1):
                if fp and len(fp):
                    print(f"[+] [{i}/{len(res)}] Mapping Table Downloaded to {fp}")
                else:
                    print(f"[-] [{i}/{len(res)}] Mapping Table Download failed")
        except:
            print("[!]" + " WARNING ".center(54, "="))
            print('[!]' + '-- GITHUB CONNECTION FAILED --'.center(54))
            print('[!]' + 'Failed to check for updates'.center(54))
            print('[!]' + '& update the mapping table'.center(54))
            print("[!]" + "".center(54, "="))
            try:
                etree.parse(str(Path.home() / '.local' / 'share' / 'mdc' / 'mapping_actor.xml'))
            except:
                print('[!]' + "Failed to load mapping table".center(54))
                print('[!]' + "".center(54, "="))
    # åˆ›å»ºå¤„ç†å¤±è´¥æ–‡ä»¶å¤¹
    create_failed_folder(G_conf.failed_folder())

    # create OpenCC converter
    ccm = G_conf.cc_convert_mode()
    # 0: no convert, 1: t2s, 2: s2t
    try:
        oCC = None if ccm == 0 else OpenCC('t2s.json' if ccm == 1 else 's2t.json')
    except:
        # some OS no OpenCC cpython, try opencc-python-reimplemented.
        # pip uninstall opencc && pip install opencc-python-reimplemented
        oCC = None if ccm == 0 else OpenCC('t2s' if ccm == 1 else 's2t')
    # æœç´¢æ¨¡å¼
    if not search == '':
        search_list = search.split(",")
        for i in search_list:
            json_data = get_data_from_json(i, oCC, None, None)
            debug_print(json_data)
            time.sleep(int(config.getInstance().sleep()))
        os._exit(0)
    # å•æ–‡ä»¶å¤„ç†
    if not single_file_path == '':  # Single File
        print('[+]==================== Single File =====================')
        if custom_number == '':
            create_data_and_move_with_custom_number(single_file_path,
                                                    get_number(G_conf.debug(), os.path.basename(single_file_path)), oCC,
                                                    specified_source, specified_url)
        else:
            create_data_and_move_with_custom_number(single_file_path, custom_number, oCC,
                                                    specified_source, specified_url)
    else:
        # æ–‡ä»¶å¤¹å¤„ç†
        folder_path = G_conf.source_folder()
        if not isinstance(folder_path, str) or folder_path == '':
            folder_path = os.path.abspath("..")

        # è¯»å– æµ‹è¯•æ–‡ä»¶é‡Œçš„ç”µå½±è·¯å¾„ æˆ– æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
        def _get_movie_list():
            if (test_movie_list_path := G_ini_conf.common.test_movie_list) and os.path.isfile(test_movie_list_path):
                return [line.strip() for line in open(test_movie_list_path, encoding='utf-8') if line.strip()]
            else:
                return movie_lists(folder_path, regexstr)

        movie_list = _get_movie_list()
        code_ep_paths = get_numbers(movie_list)
        print('| æ ¹æ®è·¯å¾„æ–‡ä»¶åè¯†åˆ«çš„ç•ªå·ä¿¡æ¯,è¯·ç¡®è®¤è¯†åˆ«çš„ä¿¡æ¯æ— è¯¯')
        [print('|', i.path, '\n|    ','|ğŸ“Ÿ', i.result.code,'ğŸ“Ÿ|ğŸ“š',i.result.episode,'ğŸ“š|ğŸ’¬ğŸ‡¨ğŸ‡³',i.result.isCn) for i in code_ep_paths]
        print('|======================================================')


        count = 0
        count_all = str(len(movie_list))
        print('[+]Find', count_all, 'movies.', 'main_mode:', G_ini_conf.common.main_mode.name)
        print('[*]======================================================')

        # ç»ˆç«¯è¾“å‡º 'æ˜¯å¦ç»§ç»­?, y æˆ–è€… enter æ¡ˆä»¶ç»§ç»­,å…¶ä»–é”®é€€å‡º'
        if not input('[?]ç»§ç»­? ( â€˜yâ€™æˆ–è€…ç›´æ¥å›è½¦ç»§ç»­, å…¶ä»–ä»»æ„æ¡ˆä»¶é€€å‡º): ') in ('', 'y'):
            print('[!]Exit.')
            os._exit(0)

        # è·å–åœæ­¢è®¡æ•°,ç”¨äºé™åˆ¶è¿ç»­å¤„ç†çš„æ–‡ä»¶æ•°é‡
        stop_count = G_conf.stop_counter()
        if stop_count < 1:
            stop_count = 999999
        else:
            count_all = str(min(len(movie_list), stop_count))
        # å…ˆè·å–éå†ç”µå½±åˆ—è¡¨,æå–ä¸è”ç½‘çš„å½±ç‰‡ä¿¡æ¯, æ¯”å¦‚: åˆ†é›†,æ˜¯å¦å†…åµŒä¸­æ–‡,æ˜¯å¦æ³„æ¼ç‰ˆ,æ˜¯å¦å»é©¬èµ›å…‹ç‰ˆ

        for movie_path in movie_list:  # éå†ç”µå½±åˆ—è¡¨ äº¤ç»™coreå¤„ç†
            count = count + 1
            percentage = str(count / int(count_all) * 100)[:4] + '%'
            print('[!] {:>30}{:>21}'.format('- ' + percentage + ' [' + str(count) + '/' + count_all + '] -',
                                            time.strftime("%H:%M:%S")))
            # â¤ï¸ æ ¸å¿ƒå¤„ç†é€»è¾‘ â¤ï¸
            create_data_and_move(movie_path, zero_op, no_net_op, oCC)
            # å¦‚æœåœæ­¢è®¡æ•°å¤§äº0,å¹¶ä¸”å·²ç»å¤„ç†çš„æ–‡ä»¶æ•°é‡å¤§äºç­‰äºåœæ­¢è®¡æ•°,åˆ™é€€å‡ºå¾ªç¯,ç­‰å¾…ä¸‹æ¬¡å¯åŠ¨
            if count >= stop_count:
                print("[!]Stop counter triggered!")
                break
            sleep_seconds = random.randint(G_conf.sleep(), G_conf.sleep() + 2)
            time.sleep(sleep_seconds)

    if G_conf.del_empty_folder() and not zero_op:
        rm_empty_folder(G_conf.success_folder())
        rm_empty_folder(G_conf.failed_folder())
        if len(folder_path):
            rm_empty_folder(folder_path)

    end_time = time.time()
    total_time = str(timedelta(seconds=end_time - start_time))
    print("[+]Running time", total_time[:len(total_time) if total_time.rfind('.') < 0 else -3],
          " End at", time.strftime("%Y-%m-%d %H:%M:%S"))

    print("[+]All finished!!!")

    return close_logfile(logdir)


# ä»æ—¥å¿—è·å– å¤„ç†åçš„ç»“æœ
def getResultNumbers(logfile):
    """ ä»æ—¥å¿—è·å– å¤„ç†åçš„ç»“æœ 
    :param logfile: æ—¥å¿—æ–‡ä»¶
    :return: æ‰«ææ•°ï¼Œå¤„ç†æ•°ï¼ŒæˆåŠŸæ•°
    """
    try:
        if not (isinstance(logfile, Path) and logfile.is_file()):
            raise FileNotFoundError('log file not found')
        logtxt = logfile.read_text(encoding='utf-8')
        numberOfScaned = int(re.findall(r'\[\+]Find (.*) movies\.', logtxt)[0])
        numberOfProcessed = int(re.findall(r'\[1/(.*?)] -', logtxt)[0])
        numberOfSuccess = logtxt.count(r'[+]Wrote!')
        return numberOfScaned, numberOfProcessed, numberOfSuccess
    except:
        return None, None, None


# æ—¥æœŸè½¬æ¢
def period(delta, pattern):
    d = {'d': delta.days}
    d['h'], rem = divmod(delta.seconds, 3600)
    d['m'], d['s'] = divmod(rem, 60)
    return pattern.format(**d)


# é¦–å…ˆè¯»å–é…ç½®æ–‡ä»¶çš„é…ç½®ï¼Œç„¶åè¯»å–å‘½ä»¤è¡Œçš„é…ç½®ï¼Œæœ€åè¯»å–ç¯å¢ƒå˜é‡çš„é…ç½®
G_conf = config.getInstance()
global G_ini_conf
G_ini_conf = ConfigModel.get_config(Path.cwd() / "MDC/config.ini")
# ä»£ç å…¥å£
if __name__ == '__main__':
    version = '6.6.7'
    urllib3.disable_warnings()  # Ignore http proxy warning
    app_start_time = time.time()

    # Parse command line args and override config.ini
    args = tuple(argparse_function(version, G_conf))

    # é«˜çº§ç¡çœ æ¨¡å¼: è‡ªåŠ¨å‘¨æœŸè¿è¡Œ
    # é—´éš”æ—¶é—´å¤§äº0 ä¸” åœæ­¢è®¡æ•°å¤§äº0
    interval = G_ini_conf.advenced_sleep.rerun_delay  # G_conf.rerun_delay()

    if interval > 0 and G_ini_conf.advenced_sleep.stop_counter > 0:
        while True:
            try:
                # å¼€å§‹å¤„ç† â¤ï¸
                logfile = main(args)
                (numberOfScaned, numberOfProcessed, numberOfSuccess) = resultTuple = tuple(getResultNumbers(logfile))
                if all(isinstance(v, int) for v in resultTuple):
                    # æœªå¤„ç†çš„ä¸ªæ•°
                    numberOfNotProcessed = numberOfScaned - numberOfProcessed
                    # å¤„ç†ç”¨æ—¶
                    processTime = timedelta(seconds=time.time() - app_start_time)
                    print(
                        f'All movies:{numberOfScaned}  processed:{numberOfProcessed}  successes:{numberOfSuccess}  remain:{numberOfNotProcessed}' +
                        '  Elapsed time {}'.format(
                            period(processTime, "{d} day {h}:{m:02}:{s:02}") if processTime.days == 1
                            else period(processTime, "{d} days {h}:{m:02}:{s:02}") if processTime.days > 1
                            else period(processTime, "{h}:{m:02}:{s:02}")))
                    if numberOfNotProcessed == 0:
                        break
                    dateOfNextRun = datetime.now() + timedelta(seconds=interval)
                    print(
                        f'Next run time: {dateOfNextRun.strftime("%H:%M:%S")}, rerun_delay={interval}, press Ctrl+C stop run.')
                    time.sleep(interval)
                else:
                    break
            except:
                break
    else:
        # æ™®é€šæ¨¡å¼: è¿è¡Œä¸€æ¬¡
        # å¼€å§‹å¤„ç†
        main(args)

    if not G_ini_conf.common.auto_exit:
        if sys.platform == 'win32':
            input("Press enter key exit, you can check the error message before you exit...")
